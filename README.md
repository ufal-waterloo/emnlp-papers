# EMNLP Papers 2023

- [Theory of Mind for Multi-Agent Collaboration via Large Language Models](emnlp-papers/Theory-of-Mind.pdf);
- [GPTAraEval: A Comprehensive Evaluation of ChatGPT on Arabic NLP](emnlp-papers/GPTAraEval.pdf);
- [Evaluating Object Hallucination in Large Vision-Language Models](emnlp-papers/ufal-waterloo/emnlp-papers/Object-Hallucination.pdf);
- [Continually Improving Extractive QA via Human Feedback](emnlp-papers/Improving-Extractive-QA.pdf);
- [Using Interpretation Methods for Model Enhancement](emnlp-papers/Interpretation-Methods.pdf);
- [Diversity Enhanced Narrative Question Generation for Storybooks](emnlp-papers/Storybooks.pdf);
- HalOmi: A Manually Annotated Benchmark for Multilingual Hallucination and Omission Detection in Machine Translation;
- Analyzing Norm Violations in Live-Stream Chat;
- Large Language Models Can Self-Improve;
- CodeT5+: Open Code Large Language Models for Code Understanding and Generation;
- Clinical Contradiction Detection;
- Unveiling the Implicit Toxicity in Large Language Models;
- ALCUNA: Large Language Models Meet New Knowledge;
- Evaluating Cross-Domain Text-to-SQL Models and Benchmarks;
- Building Persona Consistent Dialogue Agents with Offline Reinforcement Learning;
- ``Fifty Shades of Bias’’: Normative Ratings of Gender Bias in GPT Generated English Text;
- OpenAsp: A Benchmark for Multi-document Open Aspect-based Summarization;
- RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation;
- DEPN: Detecting and Editing Privacy Neurons in Pretrained Language Models;
- API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs;
- Language and Mental Health: Measures of Emotion Dynamics from Text as Linguistic Biosocial Markers;
- SLOG: A Structural Generalization Benchmark for Semantic Parsing;
- ROBBIE: Robust Bias Evaluation of Large Generative Language Models;
- A Rose by Any Other Name would not Smell as Sweet: Social Bias in Names Mistranslation;
- Towards Building More Robust NER datasets: An Empirical Study on NER Dataset Bias from a Dataset Difficulty View;
- Non-Programmers Can Label Programs Indirectly via Active Examples: A Case Study with Text-to-SQL;
- COHESENTIA: A Novel Benchmark of Incremental versus Holistic Assessment of Coherence in Generated Texts;
- SciRepEval: A Multi-Format Benchmark for Scientific Document Representations;
- A Diachronic Perspective on User Trust in AI under Uncertainty;
- Cross-lingual Transfer Can Worsen Bias in Sentiment Analysis;
- Rumor Detection on Social Media with Crowd Intelligence and ChatGPT-Assisted Networks;
- The BLA Benchmark: Investigating Basic Language Abilities of Pre-Trained Multimodal Models;
- HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models;
- Centering the Margins: Outlier-Based Identification of Harmed Populations in Toxicity Detection;
- AD-NLP: A Benchmark for Anomaly Detection in Natural Language Processing;
- Unlearn What You Want to Forget: Efficient Unlearning for LLMs;
- Doolittle: Benchmarks and Corpora for Academic Writing Formalization;
- How do languages influence each other? Studying cross-lingual data sharing during LM fine-tuning;
- BLESS: Benchmarking Large Language Models on Sentence Simplification;
- CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code;
- AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages;
- Multilingual Holistic Bias: Extending Descriptors and Patterns to Unveil Demographic Biases in Languages at Scale;
- GlobalBench: A Benchmark for Global Progress in Natural Language Processing;
- Exploring the Boundaries of GPT-4 in Radiology;
- Dr ChatGPT tell me what I want to hear: How different prompts impact health answer correctness;
- Multilingual Simplification of Medical Texts;
- Target-Agnostic Gender-Aware Contrastive Learning for Mitigating Bias in Multilingual Machine Translation.  
